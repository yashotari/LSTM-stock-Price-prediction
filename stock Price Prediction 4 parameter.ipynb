{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "385ead7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7c54ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(\"../DSML25/Google_Stock_Price_Train.csv\")\n",
    "df_test=pd.read_csv(\"../DSML25/Google_Stock_Price_Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cde1452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/3/2012</td>\n",
       "      <td>325.25</td>\n",
       "      <td>332.83</td>\n",
       "      <td>324.97</td>\n",
       "      <td>663.59</td>\n",
       "      <td>7,380,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/4/2012</td>\n",
       "      <td>331.27</td>\n",
       "      <td>333.87</td>\n",
       "      <td>329.08</td>\n",
       "      <td>666.45</td>\n",
       "      <td>5,749,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/5/2012</td>\n",
       "      <td>329.83</td>\n",
       "      <td>330.75</td>\n",
       "      <td>326.89</td>\n",
       "      <td>657.21</td>\n",
       "      <td>6,590,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/6/2012</td>\n",
       "      <td>328.34</td>\n",
       "      <td>328.77</td>\n",
       "      <td>323.68</td>\n",
       "      <td>648.24</td>\n",
       "      <td>5,405,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/9/2012</td>\n",
       "      <td>322.04</td>\n",
       "      <td>322.29</td>\n",
       "      <td>309.46</td>\n",
       "      <td>620.76</td>\n",
       "      <td>11,688,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>12/23/2016</td>\n",
       "      <td>790.90</td>\n",
       "      <td>792.74</td>\n",
       "      <td>787.28</td>\n",
       "      <td>789.91</td>\n",
       "      <td>623,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>12/27/2016</td>\n",
       "      <td>790.68</td>\n",
       "      <td>797.86</td>\n",
       "      <td>787.66</td>\n",
       "      <td>791.55</td>\n",
       "      <td>789,100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>12/28/2016</td>\n",
       "      <td>793.70</td>\n",
       "      <td>794.23</td>\n",
       "      <td>783.20</td>\n",
       "      <td>785.05</td>\n",
       "      <td>1,153,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>12/29/2016</td>\n",
       "      <td>783.33</td>\n",
       "      <td>785.93</td>\n",
       "      <td>778.92</td>\n",
       "      <td>782.79</td>\n",
       "      <td>744,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>12/30/2016</td>\n",
       "      <td>782.75</td>\n",
       "      <td>782.78</td>\n",
       "      <td>770.41</td>\n",
       "      <td>771.82</td>\n",
       "      <td>1,770,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1258 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date    Open    High     Low   Close      Volume\n",
       "0       1/3/2012  325.25  332.83  324.97  663.59   7,380,500\n",
       "1       1/4/2012  331.27  333.87  329.08  666.45   5,749,400\n",
       "2       1/5/2012  329.83  330.75  326.89  657.21   6,590,300\n",
       "3       1/6/2012  328.34  328.77  323.68  648.24   5,405,900\n",
       "4       1/9/2012  322.04  322.29  309.46  620.76  11,688,800\n",
       "...          ...     ...     ...     ...     ...         ...\n",
       "1253  12/23/2016  790.90  792.74  787.28  789.91     623,400\n",
       "1254  12/27/2016  790.68  797.86  787.66  791.55     789,100\n",
       "1255  12/28/2016  793.70  794.23  783.20  785.05   1,153,800\n",
       "1256  12/29/2016  783.33  785.93  778.92  782.79     744,300\n",
       "1257  12/30/2016  782.75  782.78  770.41  771.82   1,770,000\n",
       "\n",
       "[1258 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42bf9b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Volume'] = df_train['Volume'].str.replace(',', '').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fba5446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1258 entries, 0 to 1257\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Date    1258 non-null   object \n",
      " 1   Open    1258 non-null   float64\n",
      " 2   High    1258 non-null   float64\n",
      " 3   Low     1258 non-null   float64\n",
      " 4   Close   1258 non-null   object \n",
      " 5   Volume  1258 non-null   float64\n",
      "dtypes: float64(4), object(2)\n",
      "memory usage: 59.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad12171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df_train[['Open','High','Low','Volume']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "848b3a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        7380500.0\n",
       "1        5749400.0\n",
       "2        6590300.0\n",
       "3        5405900.0\n",
       "4       11688800.0\n",
       "           ...    \n",
       "1253      623400.0\n",
       "1254      789100.0\n",
       "1255     1153800.0\n",
       "1256      744300.0\n",
       "1257     1770000.0\n",
       "Name: Volume, Length: 1258, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4c3fe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(x)\n",
    "x_train_scaled=scaler.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1815a5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1258, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e44047f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08581368, 0.09640129, 0.09044931, 0.29525831],\n",
       "       [0.09701243, 0.09834351, 0.09823458, 0.22993592],\n",
       "       [0.09433366, 0.09251685, 0.09408623, 0.26361233],\n",
       "       ...,\n",
       "       [0.95725128, 0.95807422, 0.95844067, 0.04589107],\n",
       "       [0.93796041, 0.94257381, 0.95033338, 0.02949139],\n",
       "       [0.93688146, 0.93669113, 0.93421352, 0.07056868]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f38ec7ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1198, 60, 4), (1198, 4))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows=[]\n",
    "y_train=[]\n",
    "for i in range(1198):#(1258 rows-60 days)\n",
    "    row=x_train_scaled[i:60+i,:]\n",
    "    rows.append(row)\n",
    "    y_train.append(x_train_scaled[60+i,:])\n",
    "x_train=np.array(rows)\n",
    "y_train=np.array(y_train)\n",
    "x_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cf3113d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08581368, 0.09640129, 0.09044931, 0.29525831],\n",
       "       [0.09701243, 0.09834351, 0.09823458, 0.22993592],\n",
       "       [0.09433366, 0.09251685, 0.09408623, 0.26361233],\n",
       "       [0.09156187, 0.08881917, 0.08800576, 0.21617942],\n",
       "       [0.07984225, 0.07671765, 0.06106986, 0.46779736],\n",
       "       [0.0643277 , 0.06444805, 0.05697833, 0.35306768],\n",
       "       [0.0585423 , 0.06033951, 0.06095621, 0.19262715],\n",
       "       [0.06568569, 0.063589  , 0.06603273, 0.15044053],\n",
       "       [0.06109085, 0.05806114, 0.06089938, 0.18517821],\n",
       "       [0.06639259, 0.06274861, 0.0652561 , 0.15317982],\n",
       "       [0.0614257 , 0.06463481, 0.06190332, 0.22171005],\n",
       "       [0.07474514, 0.07113377, 0.07071147, 0.50660392],\n",
       "       [0.02797827, 0.02463257, 0.0237536 , 0.84997597],\n",
       "       [0.02379269, 0.02244757, 0.02513638, 0.27406488],\n",
       "       [0.02409033, 0.02153249, 0.02026822, 0.24535443],\n",
       "       [0.0159238 , 0.01318468, 0.00930065, 0.40067281],\n",
       "       [0.01078949, 0.00926289, 0.00757691, 0.25905487],\n",
       "       [0.00967334, 0.01469737, 0.01208516, 0.29051262],\n",
       "       [0.01642607, 0.01439857, 0.01593044, 0.18704445],\n",
       "       [0.02100231, 0.01811493, 0.01757842, 0.1719183 ],\n",
       "       [0.02280676, 0.01951557, 0.02134793, 0.18625551],\n",
       "       [0.02273235, 0.02035595, 0.0241135 , 0.19381258],\n",
       "       [0.02810849, 0.03027247, 0.0297583 , 0.2544173 ],\n",
       "       [0.03212665, 0.04306497, 0.03538415, 0.29550661],\n",
       "       [0.0433812 , 0.04173903, 0.04457115, 0.16787345],\n",
       "       [0.04475779, 0.04355053, 0.04549932, 0.14731678],\n",
       "       [0.04790163, 0.04648253, 0.04951508, 0.1817541 ],\n",
       "       [0.0440695 , 0.0405625 , 0.04479845, 0.18661594],\n",
       "       [0.04648783, 0.04586625, 0.05048113, 0.14570284],\n",
       "       [0.04745517, 0.04416681, 0.04551826, 0.14469363],\n",
       "       [0.04873875, 0.04502587, 0.04343461, 0.19471366],\n",
       "       [0.03936305, 0.04119745, 0.03888847, 0.20315579],\n",
       "       [0.04137213, 0.04009562, 0.04330202, 0.19657589],\n",
       "       [0.04034898, 0.04963864, 0.04373769, 0.19912695],\n",
       "       [0.04784582, 0.0486115 , 0.04735566, 0.15782139],\n",
       "       [0.04325099, 0.04037574, 0.04135096, 0.16489387],\n",
       "       [0.04356723, 0.04383065, 0.04621912, 0.15529435],\n",
       "       [0.04286033, 0.04450296, 0.04580239, 0.14551061],\n",
       "       [0.04602277, 0.0513941 , 0.04828383, 0.22861434],\n",
       "       [0.05398467, 0.05680991, 0.05565237, 0.25187425],\n",
       "       [0.05738894, 0.05690328, 0.05815275, 0.1795795 ],\n",
       "       [0.05714711, 0.05531589, 0.06019851, 0.1261674 ],\n",
       "       [0.05569611, 0.05391525, 0.05176921, 0.12777333],\n",
       "       [0.04421832, 0.04119745, 0.03521367, 0.25488987],\n",
       "       [0.04514845, 0.04340112, 0.04656008, 0.10134161],\n",
       "       [0.04605997, 0.04369993, 0.0470147 , 0.10784942],\n",
       "       [0.04412531, 0.04407343, 0.04102894, 0.21438526],\n",
       "       [0.03675869, 0.03951669, 0.04032808, 0.13386063],\n",
       "       [0.04486941, 0.04960128, 0.04625701, 0.18023228],\n",
       "       [0.05065481, 0.05419538, 0.05372026, 0.23579495],\n",
       "       [0.05214302, 0.05486769, 0.05502728, 0.19545054],\n",
       "       [0.05612397, 0.05710871, 0.05995227, 0.24492992],\n",
       "       [0.05818885, 0.06767886, 0.06106986, 0.17436524],\n",
       "       [0.06540665, 0.06653968, 0.06675254, 0.12352823],\n",
       "       [0.06882953, 0.07709115, 0.07169647, 0.19822587],\n",
       "       [0.07243843, 0.07839842, 0.0702758 , 0.19345214],\n",
       "       [0.07993526, 0.07811829, 0.07961434, 0.1556628 ],\n",
       "       [0.07846566, 0.07903337, 0.0783452 , 0.14593512],\n",
       "       [0.08034452, 0.08276841, 0.08330808, 0.16105326],\n",
       "       [0.08497656, 0.08751191, 0.08921806, 0.20379656]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32533320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.08581368, 0.09640129, 0.09044931, 0.29525831],\n",
       "        [0.09701243, 0.09834351, 0.09823458, 0.22993592],\n",
       "        [0.09433366, 0.09251685, 0.09408623, 0.26361233],\n",
       "        ...,\n",
       "        [0.07846566, 0.07903337, 0.0783452 , 0.14593512],\n",
       "        [0.08034452, 0.08276841, 0.08330808, 0.16105326],\n",
       "        [0.08497656, 0.08751191, 0.08921806, 0.20379656]],\n",
       "\n",
       "       [[0.09701243, 0.09834351, 0.09823458, 0.22993592],\n",
       "        [0.09433366, 0.09251685, 0.09408623, 0.26361233],\n",
       "        [0.09156187, 0.08881917, 0.08800576, 0.21617942],\n",
       "        ...,\n",
       "        [0.08034452, 0.08276841, 0.08330808, 0.16105326],\n",
       "        [0.08497656, 0.08751191, 0.08921806, 0.20379656],\n",
       "        [0.08627874, 0.08564439, 0.08283452, 0.15438526]],\n",
       "\n",
       "       [[0.09433366, 0.09251685, 0.09408623, 0.26361233],\n",
       "        [0.09156187, 0.08881917, 0.08800576, 0.21617942],\n",
       "        [0.07984225, 0.07671765, 0.06106986, 0.46779736],\n",
       "        ...,\n",
       "        [0.08497656, 0.08751191, 0.08921806, 0.20379656],\n",
       "        [0.08627874, 0.08564439, 0.08283452, 0.15438526],\n",
       "        [0.08471612, 0.08274973, 0.07970905, 0.18545455]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.92106928, 0.92416008, 0.93248977, 0.05089708],\n",
       "        [0.92438053, 0.92909033, 0.9389112 , 0.04779736],\n",
       "        [0.93048218, 0.93536519, 0.94413926, 0.05820184],\n",
       "        ...,\n",
       "        [0.95475854, 0.95637477, 0.96863161, 0.03861834],\n",
       "        [0.95204256, 0.95529161, 0.96616912, 0.02464958],\n",
       "        [0.95163331, 0.96485331, 0.96688892, 0.03128554]],\n",
       "\n",
       "       [[0.92438053, 0.92909033, 0.9389112 , 0.04779736],\n",
       "        [0.93048218, 0.93536519, 0.94413926, 0.05820184],\n",
       "        [0.9299055 , 0.93239584, 0.9439309 , 0.04256308],\n",
       "        ...,\n",
       "        [0.95204256, 0.95529161, 0.96616912, 0.02464958],\n",
       "        [0.95163331, 0.96485331, 0.96688892, 0.03128554],\n",
       "        [0.95725128, 0.95807422, 0.95844067, 0.04589107]],\n",
       "\n",
       "       [[0.93048218, 0.93536519, 0.94413926, 0.05820184],\n",
       "        [0.9299055 , 0.93239584, 0.9439309 , 0.04256308],\n",
       "        [0.93113327, 0.93086447, 0.93485755, 0.03705647],\n",
       "        ...,\n",
       "        [0.95163331, 0.96485331, 0.96688892, 0.03128554],\n",
       "        [0.95725128, 0.95807422, 0.95844067, 0.04589107],\n",
       "        [0.93796041, 0.94257381, 0.95033338, 0.02949139]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.reshape(x_train.shape[0],x_train.shape[1],4)\n",
    "#x_train=x_train.reshape(1198,60,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d47a154",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a5367e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a78fad74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(LSTM(50,return_sequences=True,input_shape=(x_train.shape[1], 4)))\n",
    "model.add(LSTM(50,return_sequences=True))\n",
    "model.add(LSTM(50,return_sequences=True))\n",
    "model.add(LSTM(40,return_sequences=False))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b7f750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "38/38 [==============================] - 25s 150ms/step - loss: 0.0615\n",
      "Epoch 2/64\n",
      "38/38 [==============================] - 5s 118ms/step - loss: 0.0530\n",
      "Epoch 3/64\n",
      "38/38 [==============================] - 4s 120ms/step - loss: 0.0512\n",
      "Epoch 4/64\n",
      "38/38 [==============================] - 4s 97ms/step - loss: 0.0505\n",
      "Epoch 5/64\n",
      "38/38 [==============================] - 4s 110ms/step - loss: 0.0501\n",
      "Epoch 6/64\n",
      "38/38 [==============================] - 4s 111ms/step - loss: 0.0500\n",
      "Epoch 7/64\n",
      "38/38 [==============================] - 4s 100ms/step - loss: 0.0502\n",
      "Epoch 8/64\n",
      "38/38 [==============================] - 4s 105ms/step - loss: 0.0495\n",
      "Epoch 9/64\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 0.0494\n",
      "Epoch 10/64\n",
      "38/38 [==============================] - 4s 111ms/step - loss: 0.0493\n",
      "Epoch 11/64\n",
      "38/38 [==============================] - 4s 95ms/step - loss: 0.0493\n",
      "Epoch 12/64\n",
      "38/38 [==============================] - 4s 106ms/step - loss: 0.0491\n",
      "Epoch 13/64\n",
      "38/38 [==============================] - 5s 137ms/step - loss: 0.0490\n",
      "Epoch 14/64\n",
      "38/38 [==============================] - 4s 112ms/step - loss: 0.0489\n",
      "Epoch 15/64\n",
      "38/38 [==============================] - 6s 149ms/step - loss: 0.0490\n",
      "Epoch 16/64\n",
      "38/38 [==============================] - 5s 143ms/step - loss: 0.0489\n",
      "Epoch 17/64\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 0.0487\n",
      "Epoch 18/64\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 0.0489\n",
      "Epoch 19/64\n",
      "38/38 [==============================] - 4s 110ms/step - loss: 0.0487\n",
      "Epoch 20/64\n",
      "38/38 [==============================] - 4s 94ms/step - loss: 0.0485\n",
      "Epoch 21/64\n",
      "38/38 [==============================] - 5s 128ms/step - loss: 0.0488\n",
      "Epoch 22/64\n",
      "38/38 [==============================] - 3s 90ms/step - loss: 0.0486\n",
      "Epoch 23/64\n",
      "38/38 [==============================] - 4s 115ms/step - loss: 0.0484\n",
      "Epoch 24/64\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 0.0486\n",
      "Epoch 25/64\n",
      "38/38 [==============================] - 4s 100ms/step - loss: 0.0484\n",
      "Epoch 26/64\n",
      "38/38 [==============================] - 4s 99ms/step - loss: 0.0484\n",
      "Epoch 27/64\n",
      "38/38 [==============================] - 4s 111ms/step - loss: 0.0483\n",
      "Epoch 28/64\n",
      "38/38 [==============================] - 4s 100ms/step - loss: 0.0483\n",
      "Epoch 29/64\n",
      "38/38 [==============================] - 5s 136ms/step - loss: 0.0484\n",
      "Epoch 30/64\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 0.0483\n",
      "Epoch 31/64\n",
      "38/38 [==============================] - 4s 117ms/step - loss: 0.0482\n",
      "Epoch 32/64\n",
      "38/38 [==============================] - 4s 106ms/step - loss: 0.0484\n",
      "Epoch 33/64\n",
      "38/38 [==============================] - 4s 109ms/step - loss: 0.0483\n",
      "Epoch 34/64\n",
      "38/38 [==============================] - 5s 127ms/step - loss: 0.0483\n",
      "Epoch 35/64\n",
      "38/38 [==============================] - 4s 111ms/step - loss: 0.0481\n",
      "Epoch 36/64\n",
      "38/38 [==============================] - 4s 103ms/step - loss: 0.0482\n",
      "Epoch 37/64\n",
      "38/38 [==============================] - 5s 120ms/step - loss: 0.0481\n",
      "Epoch 38/64\n",
      "38/38 [==============================] - 4s 116ms/step - loss: 0.0483\n",
      "Epoch 39/64\n",
      "38/38 [==============================] - 4s 101ms/step - loss: 0.0481\n",
      "Epoch 40/64\n",
      "38/38 [==============================] - 4s 109ms/step - loss: 0.0482\n",
      "Epoch 41/64\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 0.0482\n",
      "Epoch 42/64\n",
      "38/38 [==============================] - 4s 106ms/step - loss: 0.0481\n",
      "Epoch 43/64\n",
      "38/38 [==============================] - 5s 126ms/step - loss: 0.0481\n",
      "Epoch 44/64\n",
      "38/38 [==============================] - 4s 114ms/step - loss: 0.0481\n",
      "Epoch 45/64\n",
      "38/38 [==============================] - 4s 114ms/step - loss: 0.0481\n",
      "Epoch 46/64\n",
      "38/38 [==============================] - 4s 103ms/step - loss: 0.0481\n",
      "Epoch 47/64\n",
      "38/38 [==============================] - 4s 111ms/step - loss: 0.0481\n",
      "Epoch 48/64\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 0.0480\n",
      "Epoch 49/64\n",
      "38/38 [==============================] - 5s 137ms/step - loss: 0.0480\n",
      "Epoch 50/64\n",
      "38/38 [==============================] - 4s 104ms/step - loss: 0.0481\n",
      "Epoch 51/64\n",
      "38/38 [==============================] - 4s 110ms/step - loss: 0.0480\n",
      "Epoch 52/64\n",
      "38/38 [==============================] - 5s 124ms/step - loss: 0.0479\n",
      "Epoch 53/64\n",
      "38/38 [==============================] - 4s 103ms/step - loss: 0.0479\n",
      "Epoch 54/64\n",
      "38/38 [==============================] - 4s 105ms/step - loss: 0.0481\n",
      "Epoch 55/64\n",
      "38/38 [==============================] - 5s 134ms/step - loss: 0.0480\n",
      "Epoch 56/64\n",
      "38/38 [==============================] - 4s 114ms/step - loss: 0.0479\n",
      "Epoch 57/64\n",
      "38/38 [==============================] - 4s 108ms/step - loss: 0.0480\n",
      "Epoch 58/64\n",
      "38/38 [==============================] - 5s 126ms/step - loss: 0.0480\n",
      "Epoch 59/64\n",
      "38/38 [==============================] - 4s 118ms/step - loss: 0.0479\n",
      "Epoch 60/64\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 0.0479\n",
      "Epoch 61/64\n",
      "38/38 [==============================] - 4s 106ms/step - loss: 0.0480\n",
      "Epoch 62/64\n",
      "38/38 [==============================] - 4s 107ms/step - loss: 0.0479\n",
      "Epoch 63/64\n",
      "38/38 [==============================] - 5s 134ms/step - loss: 0.0479\n",
      "Epoch 64/64\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.0479"
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=32,epochs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c5d35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc390ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Volume'] = df_test['Volume'].str.replace(',', '').astype(float)\n",
    "\n",
    "x_test_scaled=scaler.transform(df_test[['Open','High','Low','Volume']])\n",
    "x_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539a9732",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=np.vstack([x_train_scaled[-60:],x_test_scaled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564fcb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4168b1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows=[]\n",
    "\n",
    "for i in range(20):\n",
    "    row=x_test[i:60+i,:]\n",
    "    rows.append(row)\n",
    "x_test=np.array(rows)\n",
    "\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404233e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=x_test.reshape(20,60,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424e32ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "yp=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d4ce54",
   "metadata": {},
   "outputs": [],
   "source": [
    "yp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fb783c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_test_scaled,c='blue')\n",
    "plt.plot(yp,c='red')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
